
---
title: "<b><br> Tresthor <br> <i> <font size='5'>Package R pour la prévision économique</i></font>  </b ><br> <br>  Rapport des Tests Économétriques"
author: |
  | Institut de la Statistique de la Polynésie française (ISPF)
  | Par Ludovic Guyot 
  | (stage 2ème année ENS de mai 2022 à août 2022)
date: '2022-07-26'
output :
   html_document : 
     number_sections: true
     toc : yes
     toc_float:
      collapsed: no
      smooth_scoll: no

---

<div align="justify">


# Introduction

Cette partie est consacrée aux tests de cointégration et à la détermination des spécifications des MCE. Les résultats des tests dépendent des données retenues et notamment de nos hypothèses sur les déflateurs, ces résultats sont donc données à titre indicatif et sont amenés à changer. Nous nous intéresserons davantage ici au processus qu'aux résultats numériques.

Il sera également question dans cette partie de proposer des variables à ajouter (non disponible dans la base de donnée utilisée actuelle) pour améliorer les spécifications. Par exemple, au vu de l'importance du tourisme en Polynésie, il pourrait être intéressant d'utiliser certains indicateur du domaine pour déterminer certain postes de la demande.

Nous proposons 3 sources documentaires pour comprendre les tests économétriques que nous allons mener. Le premier document permet de comprendre la théorie sous-jacente au test ADF alors que les 2 suivants en sont des applications sous R:


- [Tests de Dickey-Fuller augmenté](http://theses.univ-lyon2.fr/documents/getpart.php?id=lyon2.2007.brunel_j&part=127991) 
- [Tests de cointégration appliqué à R](https://www.econometrics-with-r.org/16-3-cointegration.html) 
- [Tests de non-stationarité](https://freakonometrics.hypotheses.org/2429) 

Nous ne détaillerons pas de façons précise la base théorique de chaque test mené mais nous tachons quand même de synthétiser la méthode que nous avons adopté.

Pour définir les spécifications, nous nous inspirons dans un premier temps fortement du cas appliqué à la Grande Bretagne : [guide appliqué de prévision](https://www.tresor.economie.gouv.fr/Content/other/Opale/application_tresthor_modele_uk.html). Nous reprenons les équations économétriques de ce cas appliqué et nous les modifions pour s'adapter à nos données et à l'économie polynésienne. Toutefois, nous ne traiterons pas le MCE des exportations car les exports Polynésiens concernent des marchés très spéciaux qui requièrent des indicateurs de demande mondiale trop spécifique à ce stade de la recherche. Dans un second temps, pour afiner les spécifications, nous complétons avec des variables explicatives utilisées dans le modèle OPALE en s'appuyant sur Le [guide d'utilisation du modèle Opale](https://www.tresor.economie.gouv.fr/Content/other/Opale/manuel_opale_r.html).

Nous résumons succintement ci-dessous la théorie sous-jacente aux Modèle à Correction d'Erreur dans le cas univarié :

Soient 2 variables $x_t$ et $y_t$ indépendantes l’une de l’autre et suivant chacune une marche aléatoire : 

$$x_t = x_{t-1} + ε_t$$     et   $$y_t = y_{t-1} + \nu_t$$ 
Ces 2 variables sont non stationnaires (ici on a $x_t \leadsto I(1)$ et $y_t \leadsto I(1)$, car il suffit de les différencier une seule fois pour les rendre stationnaires). Leur variance dépend en fait du temps.

Lorsque l’on régresse  à l’aide de la méthode des moindres carrés ordinaires (MCO) le modèle suivant comprenant les 2 variables non stationnaires : 
 
  
  $$y_t = ax_{t} + ε_t$$, on obtient généralement des résidus non stationnaires : $$y_t - ax_{t} = ε_t  \leadsto I(1)  $$
  
La régression effectuée est dite fallacieuse ou illusoire. Elle est caractérisée par un R^2^ et des t de Student très élevés alors que les deux variables peuvent n'avoir aucun lien entre elles.

C’est alors qu’intervient la notion de cointégration. Nous n’avons pas de régression fallacieuse lorsque les variables $x_t$ et $y_t$ sont cointégrées, c’est à dire lorsque l’on a  $$y_t - ax_{t} - b = ε_t \leadsto I(0)$$ alors même que $y_t \leadsto I(1)$ et  $x_t \leadsto I(1)$. On note alors $x_t,y_t \leadsto CI(1,1)$

L’idée sous-jacente de la cointégration est la suivante : à court terme, $x_t$ et $y_t$ peuvent avoir une évolution divergente (elles sont toutes les deux non stationnaires) mais elles vont évoluer ensemble à long terme. Il existe alors une relation stable à long terme entre $x_t$ et $y_t$. 

Le principe de test de cointégration est le suivant :

* **Etape 1** : Une condition nécessaire de cointégration est que les séries doivent être intégrées de même ordre. Si les séries ne sont pas intégrées de même ordre, elles ne peuvent être cointégrées et on s'arrête à cette étape. Il convient donc de vérifier l’ordre d’intégration des séries étudiées à l’aide par exemple du test de Dickey-Fuller.

* **Etape 2** : On estime par les MCO la relation de long terme : 
 
 $$y_t = ax_{t} + b + ε_t$$
 
 * **Etape 3** : On test la stationarité des résidus issue de cette régression : $ε_t = y_t - \hat{a}x_{t} + \hat{b}$

On remarque ici que la relation porte sur les résidus estimés et non pas sur les « vrais » résidus de l’équation de cointégration. Par conséquent, nous ne pouvons pas nous référer aux tables de Dickey-Fuller pour mener le test de stationnarité. Il faut se référer aux tables de MacKinnon. 

Si le résidu est stationnaire nous pouvons alors estimer un modèle appelé Modèle à Correction d’Erreur (MCE) qui intègre les variables en variation et en niveau (le théorème de la représentation de Granger met en évidence le lien entre cointégration et modèle à correction d’erreur). L’emploi d’un modèle à correction d’erreur dans le cas de la  cointégration permet d’obtenir des prévisions plus fiables que si on avait utilisé la relation de long terme car les résultats de l’estimation de cette relation sont faussés par la non stationnarité des séries.

Si on a deux séries cointégrées, on peut estimer le modèle à correction d’erreur (MCE) suivant : 
 
$$∆y_t = γ∆x_t + δ(y_{t-1} – ax_{t-1} –b) + υ_t $$   avec $δ < 0$ 
 
On peut remarquer que le paramètre $δ$ doit être négatif pour qu’il y ait un retour de $y_t$ à sa valeur d’équilibre de long terme qui est $ax_{t-1} + b$. En effet, lorsque $y_{t-1}$ est supérieur à  $ax_{t-1}+b$, la force de rappel ramène à l’équilibre de long terme que si $δ < 0$. 
 
Le MCE permet de modéliser conjointement les dynamiques de court terme (représentées par les variables en différence première) et de long terme (représentées par les variables en niveau) :

* La dynamique de court terme s’écrit : 
 $y_t = α_0 + α_1y_{t-1} + α_2 x_t + α_3 x_{t-1} + υ_t$
 
* La dynamique de long terme s’exprime de la manière suivante : 
 $y_t = ax_t + b + ε_t$

On peut facilement retrouver la deuxième relation à partir de la première en postulant qu'à long terme on a $y_{t-1} = y_t$  et  $x_{t-1} = x_t$. De plus on peut retrouver le MCE à partir de la dynamique de court terme.

Nous pouvons estimer le MCE de la manière suivante : 
 
* **Etape 1** : estimation par les MCO de la relation de long terme : $$y_t = ax_t + b + ε_t$$
 
* **Etape 2** : estimation par les MCO de la dynamique de court terme : $$∆y_t = γ∆x_t + δe_{t-1} + υt$$   avec  $δ < 0$
où  $e_t = y_t - \hat{a}x_{t} + \hat{b}$

Le coefficient $δ$ doit être significativement négatif. Dans le cas contraire, la spécification de type MCE n’est pas valable. 

Les équations sont donc estimées en deux étapes : 

* Estimation de la relation de long terme : dans le modèle `Opale`, les spécifications de long terme sont choisies, après tests de stationnarité, en croisant les résultats de plusieurs tests de cointégration. Nous n'utiliserons que le test ADF (*Augmented Dickey-Fuller*) dans notre étude. 
* Estimation de la dynamique de court terme. Les spécifications des dynamiques de court terme ont été choisies sur la base de
critères de robustesse (pour éviter des spécifications instables) et d’information statistique (pour rechercher des représentations parcimonieuses). Hormis le cas idéal où les résultats
des tests sont tous concordants, nous avons conservé une latitude de jugement. La priorité est donnée au sens économique des équations, qui doivent être pertinentes pour relire l’histoire économique passée et retracer au mieux la période de crise.

`Tresthor` réalise ces deux étapes avec une seule fonction, `quick_estim()`. Il est possible d'estimer hors du package `Tresthor` les coefficients économétriques et les ajouter ensuite à la base de donnée avec des fonctions dédiées (`add_coeffs()`) afin d'utiliser des techniques autres que celle utilisée par `Tresthor`. 

Les estimations que nous menons subissent un certains nombre de biais économétrique. Nous tenterons de prendre en compte les principaux mais il se peut, au vu de l'ampleur du travail économétrique, qu'il reste des points à éclaircir, notamment à cause des liens comptables multiples et parfois indirectes entre les variables économiques créés à leur construction. Les estimations pourraient ainsi souffrir de problème de multicolinéarité. De plus, étant donné que nous traitons des series temporelles, nous pourrions avoir des problèmes dus à l'autocorrélation des résidus et des variables. Le choix d'utilisation des MCE vient en partie de ce problème, mais les MCE peuvent être utilisés à tord quand l'environnement de base n'est pas propice à cette base conceptuelle.

Ces tests économétriques ont également été réalisé sur un jeu données différent, en l'occurence trimestrialisé par interpolation linéaire. Les résultats étaient pour certains MCE différents et nous aboutissions donc à des spécifications parfois différentes. Nous préciserons donc dans ce document toutes les variables intéressantes à étudier même si elle n'ont plus d'utilité avec les données utilisées dans cet exemple. Il se pourrait qu'avec des données affinées, ces variables redevienennt significatives.

Nous allons détailler le processus pour la première équation et nous laisserons seulement le code, les résultats, les interprétations, des pistes d'améliorations et de réflexions, et quelques explications concernant des choix précis pour les MCE suivants.

Avant de commencer les tests, nous créons deux nouveaux jeu de données issu de la base de donnée principale `dt_pf` après avoir lancé le code du fichier `main.R` jusqu'au fichier `src/tresthor.R` (également possible d'utiliser `dt_pf` dans son état avant estimation dans `src/tresthor.R`) :

```{r, include=F, message=F, warning=F,echo=F}
setwd("C:/Users/ludovicg/Documents/R/ludovic")

#Paramètre utilisateur:

date_debut_obs <- "2005-03-31"
date_fin_obs    <- "2018-12-31"
date_debut_estim <- "2006-03-31"
date_fin_estim <- "2018-12-31"
date_debut_prev <- "2019-03-31"
date_fin_prev   <- "2020-12-31"

#source

source("src/functions.R")
source("src/definitions.R")
source("src/extract.R")
source("src/transform.R")
source("src/tresthor.R")


```


```{r}
#dt_pf seulement sur la période d'estimation :

dt_pf1 <- dt_pf[dt_pf$date >= date_debut_estim &
                  dt_pf$date <= date_fin_estim , ]
#dt_pf sur la période d'estimation mais sans 2017 et 2018 pollués par l'investissement d'avions :

dt_pf2 <- dt_pf1[1:48, ]

```

Nous procéderons dans le même ordre que l'ordre des équations économétriques du modèle en fichier `.txt`.

# Equation Revenu Disponible Brut : eq_rdb_s14_v

## `rdb_s14_v`

Avant toute choses, il est important de visualiser la dynamique de la variable. Nous commencerons à chaque fois par la variable endogène puis ensuite nous étudierons les variables explicatives. Ceci permet à la fois de relever une possible incohérence dans la construction de la variable (problème d'échelle ou dynamique suspicieuse), de connaitre sa tendance, et d'appréhender son pouvoir explicatif (pour une variable explicative) ou sa possibilité d'être expliquée (pour une variable dépendante) :


```{r}
ggplot(data = dt_pf1
       , aes(x = date, y = log(rdb_s14_v))) +
  geom_line() +
  ggtitle(paste0("Evolution du rdb "))
```

Nous pouvons directement déceler ici que les oscilations de la variables vont être compliquées à expliquer et donc que la régression aura un R^2^ plutôt faible.

Nous utilisons ensuite la fonction `ur.df` du package `urca` afin de réaliser un test ADF. Le test ADF est un test statistique qui vise à déterminer si une série temporelle est stationnaire, c'est-à-dire si ses propriétés statistiques (espérance, variance, auto-corrélation) varient ou non dans le temps. Il consiste en fait à faire un test de racine unitaire, c'est à dire tester si $\tau$ est égale à 1 dans la spécification suivante :

$$y_t=\tau*y_{t-1}+\epsilon_t$$

Equivalent à la spécification suivante où nous testons si le coefficient $(\tau-1)$ est nul :

$$y_t-y_{t-1}=(\tau-1)*y_{t-1}+\epsilon_t$$

On retient la seconde spécification car ce sera celle utilisée par la fonction `ur.df`. Il est en effet plus lisible et plus simple de poser comme hypothèse nulle que le coefficient n'est pas significativemeny différent de 0. Si $(\tau-1)$ est nulle alors $y$ est intégré d'ordre 1 et $y$ n'est ainsi pas stationnaire. 

Cependant, cette spécification est trop simpliste et pourrait ainsi biaiser les résultats. Le test ADF consiste à tester 3 specifications différentes afin de réduire la probabilité d'erreur de conclusion. Pour chaque spécification, la fonction décide en plus automatiquement le nombre optimale de retards à intégrer dans la spécification grâce au critère d'information d'Akaike (AIC). On ne se souciera pas de la significativé des variables de retards dans les différents modèles.

Nous détaillons maintenant les 3 spécifications à tester (en omettant les retards) :

* 1ère spécification : $$y_t-y_{t-1}=(\tau-1)*y_{t-1}+\epsilon_t$$

* 2ème spécification : $$y_t-y_{t-1}=(\tau-1)*y_{t-1}+\beta_1+\epsilon_t$$ avec $\beta_1$ une constante

* 3ème spécification : $$y_t-y_{t-1}=(\tau-1)*y_{t-1}+\beta_1+\beta_2*t+\epsilon_t$$ avec $t$ permettant de prendre en compte une dérive temporelle

Dans la console, avec la fonction `ur.df`, $y_{t-1}$ sera représenté par $z.lag.1$, la constante par $(intercept)$ et la dérive temporelle par $tt$. Enfin, les différents $z.diff.lag$ correspondront aux retards en différence.

Nous procédons de manière algorythmique pour déterminer la stationarité ou la non stationarité de la série. Nous commençons d'abord par tester la régression la plus elaborée (avec constante et dérive temporelle) pour finir par la moins elaborée (sans constante, ni dérive temporelle). L'objectif est donc d'abord de tester si la constante et la dérive temporelle sont significatives. Si elles ne sont pas significatives, on passe à la spécification avec la constante uniquement. Si la constante n'est pas significative, on passe à la spécification la plus simple. On s'arrête ainsi à la spécification adéquate pour modéliser la variable en question. C'est donc seulement quand on a définit le bon modèle qu'on peut accepter ou rejetter l'hypothèse $H_0$. On accepte $H_0$ si le coefficient économétrique $(\tau-1)$ devant $y_{t-1}$ (ou $z.lag.1$ dans la console) est non significativement différent de 0 (ce qui revient à conclure que $\tau=1$), i.e. on accepte l'hypothèse de racine unitaire et donc de non stationarité. On rejette $H_0$ si ce coefficient est significatif.



```{r}
a <- ur.df(
  log(dt_pf1$rdb_s14_v),
  lags = 6,
  selectlags = "AIC",
  type = "trend"
)
summary(a)
b <- ur.df(
  log(dt_pf1$rdb_s14_v),
  lags = 6,
  selectlags = "AIC",
  type = "drift"
)
summary(b)
c <- ur.df(
  log(dt_pf1$rdb_s14_v),
  lags = 6,
  selectlags = "AIC",
  type = "none"
)
summary(c)
```

Afin d'analyser la significativité des coefficients économétriques, il convient de comparer les valeur des statistiques à des valeurs critiques adaptées au test ADF et non les valeurs critiques tabulés par Student. La console affiche les p-values en fonction des valeurs critiques de Student donc il ne faut pas analyser ces résultats directement. Il s'agit en fait de comparer le vecteur `Value of test-statistics` avec les valeurs critiques exposées dans la table tout en bas du résultat de la console. L'ordre respectif des statistiques de tests correspond au test de non-stationarité, au test de significativité de la constante (si l'argument `type` est égal à `drift` ou `trend`, sinon la valeur n'existe pas) et au test de significativité du coefficient de la dérive temporelle (si l'argument `type` est égal à `trend`, sinon la valeur n'existe pas). La première ligne des valeurs critiques concerne toujours le test de non stationarité (tau1 si `type` est `none`, tau2 si `type` est `drift`, tau3 si `type` est `trend`), la deuxième ligne concerne le test de significativité de la constante (ligne inexistante si `type` est `none`, phi1 si `type` est `drift`, phi2 si `type` est `drift`), la troisième ligne concerne le test de significativité du coefficient de la dérive temporelle (ligne inexistante si `type` est `none` ou `drift`, phi3 si `type` est `drift`). Dans les explications qui vont suivre, pour plus de clarté, nous écrirons simplement *tau* si cela concerne la valeur critique du test de non stationarité, *phi* si cela concerne la valeur critique du test de significativité de la constante, *phi3* si cela concerne la valeur critique du test de significativité du coefficient de la dérive temporelle.

L'hypothèse nulle $H_0$ de non stationarité de la série temporelle est acceptée à un seuil définit lorsque la valeur observée du test statistique, pour la variable retardée, est supérieure à la valeur critique *tau* pour le niveau de confiance choisit. On est alors dans la région d’acceptation du test car le coefficient n'est pas significativement différent de 0, et on va retenir l’hypothèse de racine unitaire, i.e. la série n’est pas stationnaire. On rejette $H_0$ si la valeur du test statistique est inférieure à tau. Ensuite si le modèle inclue une constante, on rejette l'hypothèse nulle de constante non significativement différente de 0 si la valeur de sa statistique est supérieure à la valeur critique *phi.* Enfin si le modèle inclue une dérive temporelle, on rejette l'hypothèse nulle de nullité de son coefficient si la valeur de sa statistique est supérieure à la valeur critique *phi3.*

Dans la plupart des cas nous déciderons du modèle à retenir pour le test d'intégration avec les valeurs critique définies au seuil de 5%.

Dans notre cas, dans le premier modèle, le plus élaboré, les valeurs de la constante et du coefficient de la tendance sont significativement différentes de zéro au seuil de 5%. On retient donc ce modèle. Dans ce modèle, on rejette l'hypothèse de non-stationarité car la valeur de la statistique du coefficient de la variable retardé est inférieure à $tau$ au seuil de 5%. $rdb_s14_v$ n'est donc pas intégré d'ordre 1. On laisse les 2 autres modèles à titre d'exemple. Le modèle avec constante mais sans dérive conduit à la même conclusion. Le modèle sans constante ni dérive conduit cependant à accepter l'hypthèse de non-stationarité. Cette conclusion aurait été biaisé car le modèle est trop simplificateur.


## `rs_v`

Le revenu disponible brut est majoritairement déterminé par les revenus salariés (même s'il existe d'autres déterminant : revenu d'activité hors revenus salariés, revenus de la propriété, revenu fonciers, pensions et retraites, prestations sociales). Nous examinons donc la variable `rs_v`, revenus salariés totaux. Cette variable peut être une piste pour expliquer le revenu disponible brut.

```{r}
ggplot(data = dt_pf1
       , aes(x = date, y = log(rs_v))) +
  geom_line() +
  ggtitle(paste0("Evolution des salaires"))

a <- ur.df(
  log(dt_pf1$rs_v),
  lags = 6,
  selectlags = "AIC",
  type = "trend"
)
summary(a)
b <- ur.df(
  log(dt_pf1$rs_v),
  lags = 6,
  selectlags = "AIC",
  type = "drift"
)
summary(b)
c <- ur.df(
  log(dt_pf1$rs_v),
  lags = 6,
  selectlags = "AIC",
  type = "none"
)
summary(c)

```
Avec cette variable explicative, nous ne retenons ni la constante ni la dérive dans le modèle. Le modèle simple nous conduit à accepter l'hypothèse $H_0$ de non-stationarité. La série est ainsi intégrée d'ordre 1. 

## `msalb`

On décide d'explorer une autre possibilité de variable explicative, la masse salariale. Le revenu disponible brut est la part des revenus dont dispose un ménage pour consommer épargner ou investir après avoir réglé ses cotisations sociales et impôts directs (définition INSEE). Cependant `msalb` correspond aux rémunérations brutes des salariés. Nous étudions quand même cette variable car ce qui compte n'est pas le lien comptable des variables mais la cohérence de leur dynamique et leur sens économique.

```{r}
ggplot(data = dt_pf1
       , aes(x = date, y = msalb)) +
  geom_line() +
  ggtitle(paste0("Evolution de la masse salariale "))

a <- ur.df(
  log(dt_pf1$msalb),
  lags = 6,
  selectlags = "AIC",
  type = "trend"
)
summary(a)
b <- ur.df(
  log(dt_pf1$msalb),
  lags = 6,
  selectlags = "AIC",
  type = "drift"
)
summary(b)
c <- ur.df(
  log(dt_pf1$msalb),
  lags = 6,
  selectlags = "AIC",
  type = "none"
)
summary(c)
```

`msalb` est non-stationaire et intégrée d'ordre 1.

## Régression de la relation de long terme

Nous comparons désormais les résultats des régressions de la relation de long terme entre la variable dépendante, `rdb_s14_v`, et les deux possibles variables explicatives. Attention, ces régressions sont falacieuses comme expliqué dans la partie concernant les MCE. Ce sont toutefois des résultats intéressants pour anticiper le pouvoir explicatif des variables dans les MCE et ce sont des résultats nécessaires pour la suite des tests.

```{r}
reg_rdb_s14_v_lt1 <- lm(log(rdb_s14_v) ~ log(rs_v), dt_pf1)
summary(reg_rdb_s14_v_lt1)

reg_rdb_s14_v_lt2 <- lm(log(rdb_s14_v) ~ log(msalb), dt_pf1)
summary(reg_rdb_s14_v_lt2)
```
Les 2 variables ont plus ou moins le même pouvoir explicatif.

## Test de cointégration

Nous testons maintenant la cointégration des séries. Deux séries peuvent être cointégrées si chacune d'elle est intégrée d'ordre 1 comme nous l'avons vu dans la partie consacrée aux MCE. `rdb_s14_v` n'est pas intégré donc ce test est inutile mais nous le réalisons à titre indicatif (Il s'agirait quand même de savoir si la condition d'intégration est nécessaire à la condition de cointégration). Il s'agit en fait de tester si les résidus de la régression de long terme sont stationnaires. On procède exactement comme pour les tests d'intégration. Nous testons désormais l'hypothèse $H_0$ de non stationarité des résidus. Les 2 séries sont cointégrées si nous rejetons l'hypothèse $H_0$, c'est à dire si les résidus sont stationnaires. Dans ce cas, on pourra utiliser le concept de MCE et éviter une régression falacieuse. 

Nous étudierons parfois la stationarité de résidus de régression comportant plus d'une variable explicative. Afin de réaliser un test de cointégration avec plus de 2 variables, il est nécessaire d'utiliser des outils plus sophistiqués. Nous en resterons dans cette étude à la méthode utilisée pour tester la cointégration entre 2 variables même si cela introduit des biais dans l'analyse quand nous la menons pour tester la cointégration entre 3 variables ou plus. 

Nous utilisons `none` dans l'argument `type` pour le test de cointégration. Les séries sont en effet cointégrées si les résidus de la régression de long terme forment un bruit blanc. Toutefois il peut être intéressant de savoir si les résidus sont stationnaires dans un modèle contenant une dérive temporlle. Déduction par expérience (point à éclaircir) : si les résidus sont stationnaires dans un modèle contenant une dérive temporelle, il faut alors inclure une tendance dans la régression de long terme et retester la cointégration (dans un modèle sans constante ni trend). Ceci peut surement être le cas quand au moins une des séries est intégrée d'ordre 1 dans un modèle avec dérive. Il est intéressant d'utiliser la fonction plot avec les résidus pour avoir directement l'intuition qu'il sont stationnaires ou non ou bien pour déceler une dérive temporelle. Si les résidus suivent une tendance alors il faudra le prendre en compte dans la spécification du MCE.

```{r}
res1_rdb_s14_v <- resid(reg_rdb_s14_v_lt1)
reg_rdb_s14_v_res1 <-
  ur.df(res1_rdb_s14_v,
        lags = 6,
        type = "none",
        selectlags = "AIC")
summary(reg_rdb_s14_v_res1)
plot(res1_rdb_s14_v)

res2_rdb_s14_v <- resid(reg_rdb_s14_v_lt2)
reg_rdb_s14_v_res2 <-
  ur.df(res1_rdb_s14_v,
        lags = 6,
        type = "none",
        selectlags = "AIC")
summary(reg_rdb_s14_v_res2)
plot(res2_rdb_s14_v)
```

Si on écarte le problème de stationarité de `rdb_s14_v`, on peut conclure ici que les résidus (des 2 régressions) sont stationnaires. `rdb_s14_v` est donc cointégré avec `rs_v` ainsi qu'avec `msalb`. 

## Détermination de la spécification

Nous choisissons dans le cadre expérimental de toujours favoriser une spécification suivant conceptuellement le principe des *Modèles à Correction d'Erreur* même lorsque les conditions ne sont pas toutes réunies pour le faire. En effet, les données n'étant pas figées à ce stade de l'analyse, il est préférable de s'en tenir au cadre conceptuel le plus avancée. Il s'agira par la suite, quand les données seront certaines (et notamment pour le revenu disponible brut), de refaire ce travail pour conclure sur la possibilité ou non d'utiliser un MCE.

Nous allons tester directement avec le package `Tresthor` la specification la plus appropriée. Pour ce faire, nous créons plusieurs objets thor.equation avec la fonction `create_equation` et nous estimons ces équations avec la fonction `quick_estim` (similaire à `quick_estim_all`, mais adpatée à l'estimation d'une seule équation).

`create_equation` prend en argument :

* `equation_name` : le nom de l'équation,
* `formula` : la formule de l'équation en chaine de caractère avec la même syntaxe que celle requise pour écrire le modèle en fichier `.txt`. Il est possible d'également se servir du code : `PF_model@equation_list[["equation"]][[i]]`, avec i un numéro de ligne pour appeler directement une équation depuis l'objet thor.model,
* `coefflist` : la liste des coefficients, la fonction est opérationnelle même si cet argument contient des coefficients en trop, i.e qui ne sont pas dans `formula`,
* `endogenous` : le nom de la variable endogène,

`quick_estim` prend en argument :

* `info_equations` : l'objet thor.equation créé avec `create_equation`
* `database` : la base de donnée où trouver les observations des variables de l'équation
* `estim_start` & `estim_end ` : date de début et de fin de la période d'estimation
* `coeff_lt` : les coefficients de la partie de long terme s'il y en a (`NULL` sinon)
* `const` : booléen permettant de décider d'indiquer la précence d'une constante ou non dans l'équation (`TRUE` par défaut).

Nous testons une première spécification en expliquant le revenu disponible brut par les revenus salariés. L'équation suivante consitue la forme la plus basique d'un MCE :
$$delta(1,log(rdb_s14_v))=a\_cst+a\_0*(log(lag(rdb\_s14\_v,-1))-a\_lt2*log(lag(rs\_v,-1))-a\_lt1)+a\_1*delta(1,log(rs\_v))+delta(1,af\_eq\_rdb\_s14\_v)-a\_0*lag(af\_eq\_rdb\_s14\_v,-1)$$

* Membre de gauche : On modélise avant tout une relation de court terme donc on s'intéresse au taux de croissance des variables expliquées et explicatives. Il est ainsi nécessaire de spécifier toutes les variables en log afin d'exprimer des taux de croissance. En effet, les trois expressions suivantes sont équivalentes :

$$delta(1,log(rdb\_s14\_v))=log(rdb\_s14\_v_t)-log(rdb\_s14\_v_{t-1})$$

$$delta(1,log(rdb\_s14\_v))=log(\dfrac{rdb\_s14\_v_t}{rdb\_s14\_v_{t-1}})$$

$$delta(1,log(rdb\_s14\_v))=log(\dfrac{rdb\_s14\_v_t-rdb\_s14\_v_{t-1}}{rdb\_s14\_v_{t-1}}+1)$$
Grâce aux développements limités et plus directement à l'équivalent usuel du logarythme, $ln(1+x)\sim x$ quand $x$ tend vers 0, on obtient : 

$$delta(1,log(rdb\_s14\_v))=\dfrac{rdb\_s14\_v_t-rdb\_s14\_v_t}{rdb\_s14\_v_{t-1}}$$
Cette différence première de logarythme sera ainsi utilisée pour modéliser toutes les variables en taux de croissance dans la partie de court terme, que ce soit dans le membre de gauche ou le membre de droite de l'équation.

* Membre de droite : 

  + On inclue d'abord la constante $a\_cst$. 
  + Puis on inclue les résidus de long terme de la période précédente, précédés d'un coefficient de court terme $a\_0$.  La spécification de long terme étant : $$log(rdb\_s14\_v)=a\_lt1+a\_lt2*log(rs\_v)+\epsilon_t$$ On peut trouver les résidus de long terme, $\epsilon_{t-1}$, en retranchant la variable endogène observée de sa partie simulée :  $$log(lag(rdb\_s14\_v,-1))-a\_lt2*log(lag(rs\_v,-1))-a\_lt1$$ 
  + Ensuite, on incorpore le taux de croissance de la variable explicative précédée du coefficient de court terme $a\_1$, afin d'insérer l'explication de la dynamique de court terme : $$a\_1*delta(1,log(rs\_v))$$ 
  + Il ne reste plus qu'à spécifier la dynamique des résidus. Les résidus sont également modélisés en taux de croissance : $delta(1,af\_eq\_rdb\_s14\_v)$. Cependant il faut retrancher une partie des résidus retardés. Piste de réflexion pour ce point (à revoir avec Serge) : on pourrait en fait factoriser $a\_0*lag(af\_eq\_rdb\_s14\_v,-1)$ afin de l'inclure dans la partie de long terme. Ceci explique sont signe négatif. Ce serait donc le résidu de court terme de l'équation de long terme afin de ne corriger que les résidus de long terme. L'autre partie des résidus correspondent aux résidus directs de court terme modélisés en taux de croissance. Nous obtenons finalement pour les résidus l'expression suivante : $$delta(1,af\_eq\_rdb\_s14\_v)-a\_0*lag(af\_eq\_rdb\_s14\_v,-1)$$

Attention, la partie concernant les résidus est inutile en estimation. Ils ne sont en effet pas observés mais découlent de l'estimation grâce à la différence entre observé et simulé. Ils sont utilisés en prévision. 


```{r}
create_equation(
  equation_name = "eq_rdb_s14_v",
  formula = "delta(1,log(rdb_s14_v))=a_cst+a_0*(log(lag(rdb_s14_v,-1))-a_lt2*log(lag(rs_v,-1))-a_lt1)+a_1*delta(1,log(rs_v))+delta(1,af_eq_rdb_s14_v)-a_0*lag(af_eq_rdb_s14_v,-1)",
  coefflist = c("a_cst", "a_0", "a_1", "a_2", "a_lt2", "a_lt1"),
  endogenous = "rdb_s14_v"
)
estimation <-
  quick_estim(
    thor_equation = eq_rdb_s14_v ,
    database = dt_pf,
    estim_start = as.Date(date_debut_estim),
    estim_end = as.Date(date_fin_estim),
    coeff_lt = c("a_lt1", "a_lt2")
  )
```
    
4 choses importantes à analyser :

* Le coefficient de court terme, $a\_0$, devant les résidus de long terme, doit être significativement négatif. Il constitue la force de rappel et permet de corriger l'erreur.
* Le R^2^ doit être satisfaisant
* Le coefficient de cointégration, $a\_lt2$, dans la partie de long terme, doit être significatif et du signe attendu par l'interprétation économique
* Les coefficients de court terme doivent être significatifs et du signe attendu par l'interprétation économique

Ces 4 points ne doivent pas être appréhendés pour chaque équation de manière automatique. Le modélisateur doit se laisser une marge d'interprétaion et d'adaptabilité de façon à s'adapter au contexte et aux données. La non satisfaction d'une condition n'implique pas de rejeter la spécification. Les conditions sont dans leur ordre d'importance (selon notre expérience). 

Les résultats de la régression indique que :

* Le coefficient $a\_0$ de court terme, déterminant la force de rappel (i.e. la correction d'erreur), est négatif et significatif
* La régression explique presque moitié de la variance du membre de gauche de l'équation
* Le coefficient de cointégration est significatif. La variable explicative possède un bon pouvoir explicatif à long terme (en niveau). Le signe du coefficient est bien celui attendu, le revenu disponible brut augmente en niveau quand les revenus salariés augmentent.
* Le coefficient de court terme du taux de croissance des revenus salariés est significatif au seuil de 10%. Seule la constante n'est pas significative. En effet elle est très proche de 0. Cela n'a ainsi pas d'incidence majeure. Le signe du coefficient est bien celui attendu, le taux de croissance du revenu disponible brut augmente quand le taux de croissance des revenus salariés augmente.

Etant donné les problèmes de données exposées précédemment, cette régression n'a pas encore de vrai sens mais dans le cas ou les données seraient arrêtées, nous pourrions accepter cette spécification.

Nous essayons cependant d'améliorer la spécification en testant la deuxième variable explicatives étudiées, `msalb` :

```{r}
create_equation(
  equation_name = "eq_rdb_s14_v",
  formula = "delta(1,log(rdb_s14_v))=a_cst+a_0*(log(lag(rdb_s14_v,-1))-a_lt2*log(lag(msalb,-1))-a_lt1)+a_1*delta(1,log(msalb))+delta(1,af_eq_rdb_s14_v)-a_0*lag(af_eq_rdb_s14_v,-1)",
  coefflist = c("a_cst", "a_0", "a_1", "a_2", "a_lt2", "a_lt1"),
  endogenous = "rdb_s14_v"
)

estimation <-
  quick_estim(
    thor_equation = eq_rdb_s14_v ,
    database = dt_pf,
    estim_start = as.Date(date_debut_estim),
    estim_end = as.Date(date_fin_estim),
    coeff_lt = c("a_lt1", "a_lt2")
  )
```

Les résultats sont très similaires. On retient `rs_v` qui a plus de sens économique dans le cadre de cette spécification. En effet `msalb` contient en partie les charges sociales, non déterminantes du revenu disponible brut. Lors de précédents tests avec une autre configuration de déflateur et une autre méthode de trimestrialisation, la variable `ipc_tot` pouvait être incorporée dans la partie de court terme et permettait de capter une importante partie de la variance de la variable dépendante. Les mises à jour du code ont altérées cet effet explicatif. 

S'il n'était finalement pas possible d'obtenir des données fiable pour `rdb_s14_v`, une possibilité serait de ne conserver que le MCE `eq_cf_s14` et d'expliquer la consommation finale des ménages avec `rs_v`. En effet, c'est ce que nous avons indirectement effectué avec `eq_rdb_s14_v` et il s'avère que la régression est satisfaisante. De plus, `eq_cf_s14` conserverait sa cohérence économique.

# Equation Consommation finale des ménages : `eq_cf_s14`

L'équation de la consommation finale des ménages est basée sur une relation artificielle comme on l'a vu précédemment.
`rdb_s14_v` a artificiellement été créé à partir de `cf_s14`. Or on explique `rdb_s14_v` grâce à `pa`, le pouvoir d'achat qui est simplement le revenu disponible brut déflaté. Les résultats suivants sont donc indicatifs à ce stade. Le problème du RDB n'est pas anondin car il fausse donc directement deux équations économétriques, et également la logique d'équation comptable (par exemple l'épargne obtenu avec le modèle est fausse). Ce problème est d'autant plus important que la série de valeur de la consommation finale des ménages est probablement non exacte comme expliqué dans le `Rapport de performance`. 

## `cf_s14`

```{r}
ggplot(data = dt_pf1
       , aes(x = date, y = log(cf_s14))) +
  geom_line() +
  ggtitle(paste0("Evolution de la consommation finale des ménages"))

a <- ur.df(
  log(dt_pf1$cf_s14),
  lags = 6,
  selectlags = "AIC",
  type = "trend"
)
summary(a)
b <- ur.df(
  log(dt_pf1$cf_s14),
  lags = 6,
  selectlags = "AIC",
  type = "drift"
)
summary(b)
```

La constante est significative et nous rejetons l'hypothèse nulle de non-stationarité. La série n'est pas intégrée d'ordre 1.

## `pa`

Le pouvoir d'achat, déterminé sur la base du RDB, doit être un très bon indicateur pour déterminer la consommation finale des ménages.

```{r}
ggplot(data = dt_pf1
       , aes(x = date, y = log(pa))) +
  geom_line() +
  ggtitle(paste0("Evolution du pouvoir d'achat"))

a <- ur.df(log(dt_pf1$pa),
           lags = 6,
           selectlags = "AIC",
           type = "trend")
summary(a)
b <- ur.df(log(dt_pf1$pa),
           lags = 6,
           selectlags = "AIC",
           type = "drift")
summary(b)
```

Nous retenons le modèle avec constante sans dérive temporelle, et rejetons l'hypothèse de non-stationarité. `pa` n'est pas intégré d'ordre 1.

## Régression de la relation de long terme

```{r}
reg_cf_s14_lt1 <- lm(log(cf_s14)~log(pa),dt_pf1)
summary(reg_cf_s14_lt1) 
```
La régression est forcément bonne étant donné que la relation est artificielle.

## Test de cointégration

```{r}
res1_cf_s14 <- resid(reg_cf_s14_lt1)
plot(res1_cf_s14)
reg_cf_s14_res1<-
  ur.df(res1_cf_s14,
        lags = 6,
        type = "none",
        selectlags = "AIC")
summary(reg_cf_s14_res1)
```
Les 2 séries sont cointégrées. 

## Détermination de la spécification

```{r}
create_equation(
  equation_name = "eq_cf_s14",
  formula="delta(1,log(cf_s14))=b_cst+b_0*(log(lag(cf_s14,-1))-b_lt2*log(lag(pa,-1))-b_lt1)+b_1*delta(1,log(pa))+delta(1,af_eq_cf_s14)-b_0*lag(af_eq_cf_s14,-1)",
  coefflist = c("b_cst","b_0","b_1","b_2","b_lt2","b_lt1"),
  endogenous = "cf_s14"
)
estimation <- quick_estim(thor_equation = eq_cf_s14 , database = dt_pf,
                          estim_start=as.Date(date_debut_estim),
                          estim_end=as.Date(date_fin_estim),
                          coeff_lt = c("b_lt1","b_lt2"),
                          const = T)
```

Nous observons un message d'alerte. Il est surement lié au fait que la fonction ne soit pas capable de déterminer l'écart type des coefficient estimés de long terme. La raison de ce problème est inconnue et contraint l'analyse. Il est tout de même possible d'avoir un aperçu de la significativité du coefficient d'intégration directement grâce à la régression de la relation de long terme menée plus haut. Cependant, les résultats de la régression de long terme (établit par une simple méthode de MCO) et les résultat de la partie de long terme du MCE par `Tresthor` sont différents. Pourtant la méthode 2-step des MCE consiste à mener une MCO en première étape. Il doit y avoir une subtilité dans la méthode menée (étudier plus en profondeur l'utilité de la bandwith et de la fonction de kernel ainsi que les leads et les lag paramétrés par le package).

Au delà de ce problème, la spécification est automatiquement satisfaisante. Nous pouvons néanmoins essayer de l'améliorer en incluant l'emploi pour expliquer les variations de court terme de la consommation : 

```{r}
create_equation(
  equation_name = "eq_cf_s14",
  formula = "delta(1,log(cf_s14))=b_cst+b_0*(log(lag(cf_s14,-1))-b_lt2*log(lag(pa,-1))-b_lt1)+b_1*delta(1,log(pa))+b_2*delta(1,log(emploi))+delta(1,af_eq_cf_s14)-b_0*lag(af_eq_cf_s14,-1)",
  coefflist = c("b_cst", "b_0", "b_1", "b_2", "b_lt2", "b_lt1"),
  endogenous = "cf_s14"
)
estimation <-
  quick_estim(
    thor_equation = eq_cf_s14 ,
    database = dt_pf,
    estim_start = as.Date(date_debut_estim),
    estim_end = as.Date(date_fin_estim),
    coeff_lt = c("b_lt1", "b_lt2"),
    const = T
  )
```

Dans les tests économétriques menés avec une précédente configuration, la variable `emploi` pouvait être incorporée dans la partie de court terme et permettait de capter une importante partie de la variance de la variable dépendante. Des modifications sur les déflateurs ont altéré cet effet explicatif mais nous le précisons quand même à titre indicatif. Dans le modèle `OPALE`, c'est le taux de chômage qui est utilisé pour expliqué les variations de court-terme. Il faudra donc s'interessé à la relation entre consommation des ménages et marché du travail quand les données seront définitives.

# Equation Investissement des entreprises : `eq_fbcf_s11`

## `fbcf_s11`

Nous utilisons `dt_pf2` qui ne contient pas l'année 2018 pendant laquelle plusieurs avions ont été acquis. En effet, ces achats ne pourront pas être expliqués pas les variables explicatives, cela biaiserait ainsi les estimations.

```{r}
ggplot(data = dt_pf1
       , aes(x =date, y=log(fbcf_s11))) +
  geom_line() +
  ggtitle(paste0("Evolution de l'investissement des entreprises avec 2018"))

ggplot(data = dt_pf2
       , aes(x =date, y=log(fbcf_s11))) +
  geom_line() +
  ggtitle(paste0("Evolution de l'investissement des entreprises sans 2018"))

a <- ur.df(log(dt_pf2$fbcf_s11), 
           lags = 6, 
           selectlags = "AIC", 
           type = "trend")
summary(a)
b <- ur.df(log(dt_pf2$fbcf_s11), 
           lags = 6, 
           selectlags = "AIC", 
           type = "drift")
summary(b)
c <- ur.df(log(dt_pf2$fbcf_s11), 
           lags = 6, 
           selectlags = "AIC", 
           type = "none")
summary(c)
```
Nous acceptons l'hypothèse nulle de non-stationarité dans un modèle sans constante ni dérive temporelle.

## `pib`

Les entreprises investissent en fonction de la valeur ajoutée du pays résumé par le PIB. Nous pourrions néanmoins nous intéresser au temps de mise en oeuvre et de réaction de l'investissement des entreprises face à la dynamique du pib.

```{r}
ggplot(data = dt_pf1
       , aes(x = date, y = log(pib))) +
  geom_line() +
  ggtitle(paste0("Evolution du pib"))

a <- ur.df(
  log(dt_pf1$pib),
  lags = 6,
  selectlags = "AIC",
  type = "trend"
)
summary(a)
b <- ur.df(
  log(dt_pf1$pib),
  lags = 6,
  selectlags = "AIC",
  type = "drift"
)
summary(b)
c <- ur.df(
  log(dt_pf1$pib),
  lags = 6,
  selectlags = "AIC",
  type = "none"
)
summary(c)
```
Nous acceptons l'hypothèse nulle de non-stationarité dans un modèle sans constante ni dérive temporelle.

## `va_v`

Nous étudions une troisième variable qui peut potentiellement expliquer l'investissement des entreprises : la valeur ajoutée. Cependant, elle est étroitement lié au PIB. Il faudrait ainsi réfléchir à l'intérêt qu'elle comporte face au PIB.

```{r}
ggplot(data = dt_pf1
       , aes(x = date, y = log(va_v))) +
  geom_line() +
  ggtitle(paste0("Evolution de la valeur ajoutée "))

a <- ur.df(
  log(dt_pf1$va_v),
  lags = 6,
  selectlags = "AIC",
  type = "trend"
)
summary(a)
b <- ur.df(
  log(dt_pf1$va_v),
  lags = 6,
  selectlags = "AIC",
  type = "drift"
)
summary(b)
c <- ur.df(
  log(dt_pf1$va_v),
  lags = 6,
  selectlags = "AIC",
  type = "none"
)
summary(c)

```

Nous acceptons l'hypothèse nulle de non-stationarité dans un modèle sans constante ni dérive temporelle.

## Regression de la relation de long terme


```{r}
reg_fbcf_s11_lt1 <- lm(log(fbcf_s11) ~ log(pib), dt_pf2)
summary(reg_fbcf_s11_lt1)

reg_fbcf_s11_lt2 <- lm(log(fbcf_s11) ~ log(va_v), dt_pf2)
summary(reg_fbcf_s11_lt2)
```

Le pib explique mieux l'investissement des entreprises. La valeur ajoutée est quand même une variable intéressante à revoir avec les données finales. Nous retenons pour l'instant uniquement le `pib`.

## Tests de cointégration

```{r}
res1_fbcf_s11 <- resid(reg_fbcf_s11_lt1)
plot(res1_fbcf_s11)
reg_fbcf_s11_res1 <-
  ur.df(res1_fbcf_s11,
        lags = 6,
        type = "none",
        selectlags = "AIC")
summary(reg_fbcf_s11_res1)
```

`fbcf_s11` est cointégrée avec chacune des 2 variables utilisées.

## Détermination de la spécification


```{r}
create_equation(
  equation_name = "eq_fbcf_s11",
  formula = "delta(1,log(fbcf_s11))=c_cst+c_0*(log(lag(fbcf_s11,-1))-c_lt2*log(lag(pib,-1))-c_lt1)+c_1*delta(1,log(pib))+delta(1,af_eq_fbcf_s11)-c_0*lag(af_eq_fbcf_s11,-1)",
  coefflist = c(
    "c_cst",
    "c_0",
    "c_1",
    "c_2",
    "c_3",
    "c_4",
    "c_5",
    "c_lt2",
    "c_lt1"
  ),
  endogenous = "fbcf_s11"
)
estimation <-
  quick_estim(
    thor_equation = eq_fbcf_s11,
    database = dt_pf,
    estim_start = as.Date(date_debut_estim),
    estim_end = as.Date(date_fin_estim),
    coeff_lt = c("c_lt1", "c_lt2"),
    const = T
  )
```

La relation n'est pas du tout satisfaisante. Nous essayons de résoudre le problème en inlcuant des indicatrices afin de prendre en compte les investissements d'avions. Toutefois, comme vu précédemment, la meilleure solution serait de retrancher ces avions directement dans les données d'origine.

```{r}
create_equation(
  equation_name = "eq_fbcf_s11",
  formula = "delta(1,log(fbcf_s11))=c_cst+c_0*(log(lag(fbcf_s11,-1))-c_lt2*log(lag(pib,-1))-c_lt1)+c_1*delta(1,log(pib))+c_2*dummy_avion+delta(1,af_eq_fbcf_s11)-c_0*lag(af_eq_fbcf_s11,-1)",
  coefflist = c(
    "c_cst",
    "c_0",
    "c_1",
    "c_2",
    "c_lt2",
    "c_lt1"
  ),
  endogenous = "fbcf_s11"
)
estimation <-
  quick_estim(
    thor_equation = eq_fbcf_s11,
    database = dt_pf,
    estim_start = as.Date(date_debut_estim),
    estim_end = as.Date(date_fin_estim),
    coeff_lt = c("c_lt1", "c_lt2"),
    const = T
  )
```

Inclure des indicatrices permet de faire automatiquement augmenter le R^2^. Cependant, cela ne permet pas de rendre `pib` intéressant pour expliquer les variations de court-terme de `fbcf_s11`. On décide de changer la période d'estimation pour ce MCE en excluant 2018 de la période et nous décalons `pib` d'un retard afin de prendre en compte le temps de réaction de l'investissement :


```{r}
create_equation(
  equation_name = "eq_fbcf_s11",
  formula = "delta(1,log(fbcf_s11))=c_cst+c_0*(log(lag(fbcf_s11,-1))-c_lt2*log(lag(pib,-2))-c_lt1)+c_1*delta(1,log(lag(pib,-1)))+delta(1,af_eq_fbcf_s11)-c_0*lag(af_eq_fbcf_s11,-1)",
  coefflist = c(
    "c_cst",
    "c_0",
    "c_1",
    "c_2",
    "c_lt2",
    "c_lt1"
  ),
  endogenous = "fbcf_s11"
)
estimation <-
  quick_estim(
    thor_equation = eq_fbcf_s11,
    database = dt_pf,
    estim_start = as.Date(date_debut_estim),
    estim_end = as.Date("2017-12-31"),
    coeff_lt = c("c_lt1", "c_lt2"),
    const = T
  )
```

Cette modification permet de mieux juger la relation de long-terme. Et `pib` permet de mieux expliquer les dynamique de court terme quand il est appréhender avec un retard. Toutefois le R^2^ est faible. Nous laissons dans le modèle la précédente spécification avec l'indicatrice. Il s'agira toutefois de retester la spécifications quand des choix de retraitement auront été appliqué concernant les avions;

Notons qu'il serait intéressant d'étudier le taux d'utilisation des capacités et le taux d'intérêt pour afiner la spécification.

# Equation Investissement des ménages : `eq_fbcf_s14`

## `fbcf_s14`

Le graphique questionne. On observe une importante hausse puis une baisse en 2017-2018. A revoir.

```{r}
ggplot(data = dt_pf1
       , aes(x = date, y = log(fbcf_s14))) +
  geom_line() +
  ggtitle(paste0("Evolution de l'investissement des ménages"))

a <- ur.df(
  log(dt_pf1$fbcf_s14),
  lags = 6,
  selectlags = "AIC",
  type = "trend"
)
summary(a)
b <- ur.df(
  log(dt_pf1$fbcf_s14),
  lags = 6,
  selectlags = "AIC",
  type = "drift"
)
summary(b)
c <- ur.df(
  log(dt_pf1$fbcf_s14),
  lags = 6,
  selectlags = "AIC",
  type = "none"
)
summary(c)
```

Nous acceptons l'hypothèse nulle de non-stationarité dans un modèle sans constante ni dérive temporelle.

## `px_immo`

L'investissement des ménages dépend principalement des loyers du parc locatif. Nous allons ainsi étudier `px_immo`, indicateur des prix des loyers. 

```{r}
ggplot(data = dt_pf1
       , aes(x = date, y = log(px_immo))) +
  geom_line() +
  ggtitle(paste0("Evolution du prix de l'immobilier"))

a <- ur.df(
  log(dt_pf1$px_immo),
  lags = 6,
  selectlags = "AIC",
  type = "trend"
)
summary(a)
b <- ur.df(
  log(dt_pf1$px_immo),
  lags = 6,
  selectlags = "AIC",
  type = "drift"
)
summary(b)
c <- ur.df(
  log(dt_pf1$px_immo),
  lags = 6,
  selectlags = "AIC",
  type = "none"
)
summary(c)
```

Nous acceptons l'hypothèse nulle de non-stationarité dans un modèle sans constante ni dérive temporelle.

## `ind_btp`

Nous étudions également l'indice des prix du batiment qui peut compléter le secteur locatif afin d'expliquer l'investissement des ménages.

```{r}
ggplot(data = dt_pf1
       , aes(x = date, y = log(ind_btp))) +
  geom_line() +
  ggtitle(paste0("Evolution de l'indicateur des prix du batiment"))

a <- ur.df(
  log(dt_pf1$ind_btp),
  lags = 6,
  selectlags = "AIC",
  type = "trend"
)
summary(a)
b <- ur.df(
  log(dt_pf1$ind_btp),
  lags = 6,
  selectlags = "AIC",
  type = "drift"
)
summary(b)
```

Nous pouvons difficilement accepter l'hypothèse nulle de non-stationarité (valeur du test statistique supérieur de très peu à la valeur critique au seuil de 5%) en retenant le modèle avec constante sans dérive temporelle.

## Regression de la relation de long terme


```{r}
reg_fbcf_s14_lt1 <- lm(log(fbcf_s14) ~ log(px_immo), dt_pf1)
summary(reg_fbcf_s14_lt1)

reg_fbcf_s14_lt2 <- lm(log(fbcf_s14) ~ log(ind_btp), dt_pf1)
summary(reg_fbcf_s14_lt2)
```

Les deux variables expliquent l'investissement des ménages. Il faut toutefois retenir que `ind_btp` n'est pas intégré d'ordre 1.

## Tests de cointégration

```{r}
res1_fbcf_s14 <- resid(reg_fbcf_s14_lt1)
reg_fbcf_s14_res1 <-
  ur.df(res1_fbcf_s14,
        lags = 6,
        type = "none",
        selectlags = "AIC")
summary(reg_fbcf_s14_res1)
plot(res1_fbcf_s14)
res2_fbcf_s14 <- resid(reg_fbcf_s14_lt2)
reg_fbcf_s14_res2 <-
  ur.df(res2_fbcf_s14,
        lags = 6,
        type = "none",
        selectlags = "AIC")
summary(reg_fbcf_s14_res2)
plot(res2_fbcf_s14)
```

`fbcf_s14` est cointégrée avec chacune des 2 variables utilisées.
Attention, les graphiques montrent que les résidus peuvent être temporairement non-stationnaire et ne sont pas distribué aléatoirement (auto corrélation). 

## Détermination de la spécification


```{r}
create_equation(
  equation_name = "eq_fbcf_s14",
  formula = "delta(1,log(fbcf_s14))=d_cst+d_0*(log(lag(fbcf_s14,-1))-d_lt2*log(lag(px_immo,-1))-d_lt1)+d_1*delta(1,log(px_immo))+delta(1,af_eq_fbcf_s14)-d_0*lag(af_eq_fbcf_s14,-1)",
  coefflist = c(
    "d_cst",
    "d_0",
    "d_1",
    "d_2",
    "d_lt2",
    "d_lt1"
  ),
  endogenous = "fbcf_s14"
)
estimation <-
  quick_estim(
    thor_equation = eq_fbcf_s14,
    database = dt_pf,
    estim_start = as.Date(date_debut_estim),
    estim_end = as.Date(date_fin_estim),
    coeff_lt = c("d_lt1", "d_lt2"),
    const = T
  )
```

`px_immo` explique plutôt bien `fbcf_s14` à court terme. Cependant, la correction d'erreur n'est pas satisfaisante. Nous testons une autre spécification :

```{r}
create_equation(
  equation_name = "eq_fbcf_s14",
  formula = "delta(1,log(fbcf_s14))=d_cst+d_0*(log(lag(fbcf_s14,-1))-d_lt2*log(lag(px_immo,-1))-d_lt3*tendance-d_lt1)+d_1*delta(1,log(px_immo))+d_2*delta(1,log(ind_btp))+delta(1,af_eq_fbcf_s14)-d_0*lag(af_eq_fbcf_s14,-1)",
  coefflist = c(
    "d_cst",
    "d_0",
    "d_1",
    "d_2",
    "d_lt1",
    "d_lt2",
    "d_lt3"
  ),
  endogenous = "fbcf_s14"
)
estimation <-
  quick_estim(
    thor_equation = eq_fbcf_s14,
    database = dt_pf,
    estim_start = as.Date(date_debut_estim),
    estim_end = as.Date(date_fin_estim),
    coeff_lt = c("d_lt1", "d_lt2","d_lt3" ),
    const = T
  )

```

L'ajout, dans la partie de court terme de `ind_btp` n'améliore pas de façon significative les résultats de la régression, mais on le laisse à ce stade expérimental. Un ajout important concerne la partie de long terme. En effet, comme dans le cas Grande Bretagne de la DG du trésor, on inclue une tendance dans la partie de long terme. La correction d'erreur devient davantage significative grâce à cette modification. Ceci pourrait avoir encore plus de valeur ajoutée sans la variation inexpliquée de l'investissement des ménages en 2018. Le fait d'inclure une tendance est peut-être une pratique à adopter lorsque les résidus dérives dans la régression de long terme. Ceci est à considérer.

Par exemple, si on test la cointégration avec l'ajout de la tendance, on observe une bien meilleure stationarité à la fois graphiquement et analytiquement. Nous ajoutons cette tendance uniquement dans ce MCE mais il est nécessaire d'étudier l'ajout d'une telle variable dans d'autres MCE dans la suite des recherches.

```{r}
reg_fbcf_s14_lt3 <-
  lm(log(fbcf_s14) ~ log(px_immo) + tendance, dt_pf1)
summary(reg_fbcf_s14_lt3)
res3_fbcf_s14 <- resid(reg_fbcf_s14_lt3)
reg_fbcf_s14_res3 <-
  ur.df(res3_fbcf_s14,
        lags = 6,
        type = "none",
        selectlags = "AIC")
summary(reg_fbcf_s14_res3)
plot(res3_fbcf_s14)
```

# Equation Salaire moyen par tête des salariés : `eq_smpt_s11`

## `smpt_s11`

```{r}
ggplot(data = dt_pf1
       , aes(x = date, y = log(smpt_s11))) +
  geom_line() +
  ggtitle(paste0("Evolution du salaire moyen par tête des salariés"))

a <- ur.df(
  log(dt_pf1$smpt_s11),
  lags = 6,
  selectlags = "AIC",
  type = "trend"
)
summary(a)
```

Nous rejetons l'hypothèse nulle de non-stationarité dans un modèle avec constante et dérive temporelle.

## `dfl_cf_s14`

Le déflateur de la consommation finale des méngages permet d'expliquer la dynamique du salaire en bouclant le prix au salaire.

```{r}
ggplot(data = dt_pf1
       , aes(x = date, y = log(dfl_cf_s14))) +
  geom_line() +
  ggtitle(paste0("Evolution du déflateur de la consommation finale des ménages"))

a <- ur.df(
  log(dt_pf1$dfl_cf_s14),
  lags = 6,
  selectlags = "AIC",
  type = "trend"
)
summary(a)
b <- ur.df(
  log(dt_pf1$dfl_cf_s14),
  lags = 6,
  selectlags = "AIC",
  type = "drift"
)
summary(b)
```

Nous rejetons l'hypothèse nulle de non-stationarité dans un modèle avec constante sans dérive temporelle.

## `productivite`

Nous étudions également la productivité qui peut contribuer à compléter `dfl_cf_s14`. La productivité permet d'expliquer les choix du côté de la demande de travail (au sens économique), donc les entreprises. Alors que `dfl_cf_s14` permet d'expliquer la dynamique de l'offre de travail, les ménages. 

```{r}
ggplot(data = dt_pf1
       , aes(x = date, y = log(productivite))) +
  geom_line() +
  ggtitle(paste0("Evolution de la productivité"))

a <- ur.df(
  log(dt_pf1$productivite),
  lags = 6,
  selectlags = "AIC",
  type = "trend"
)
summary(a)
b <- ur.df(
  log(dt_pf1$productivite),
  lags = 6,
  selectlags = "AIC",
  type = "drift"
)
summary(b)
c <- ur.df(
  log(dt_pf1$productivite),
  lags = 6,
  selectlags = "AIC",
  type = "none"
)
summary(c)

```

Nous acceptons l'hypothèse nulle de non-stationarité en retenant le modèle sans constante ni dérive temporelle.

## Regression de la relation de long terme


```{r}
reg_smpt_s11_lt1 <- lm(log(smpt_s11) ~ log(dfl_cf_s14), dt_pf1)
summary(reg_smpt_s11_lt1)

reg_smpt_s11_lt2 <- lm(log(smpt_s11) ~ log(productivite), dt_pf1)
summary(reg_smpt_s11_lt2)

```

`dfl_cf_s14` est une très bonne variable explicative pour la partie de long terme. `productivite` est également intéressante.

## Tests de cointégration

```{r}
res1_smpt_s11 <- resid(reg_smpt_s11_lt1)
reg_smpt_s11_res1 <-
  ur.df(res1_smpt_s11,
        lags = 6,
        type = "none",
        selectlags = "AIC")
summary(reg_smpt_s11_res1)
plot(res1_smpt_s11)
res2_smpt_s11 <- resid(reg_smpt_s11_lt2)
reg_smpt_s11_res2 <-
  ur.df(res2_smpt_s11,
        lags = 6,
        type = "none",
        selectlags = "AIC")
summary(reg_smpt_s11_res2)
plot(res2_smpt_s11)
```

`smpt_s11` est cointégrée avec `productivité`. Nous pourrions néanmoins, graphiquement, douter de la stationarité jusqu'à la 20ème observation. Concernant la cointégration avec `dfl_cf_14`, on ne peut rejeter l'hypothèse de non-stationarité qu'à un niveau de 10%. Ceci se confirme graphiquement. 

## Détermination de la spécification


```{r}
create_equation(
  equation_name = "eq_smpt_s11",
  formula="delta(1,log(smpt_s11))=e_cst+e_0*(log(lag(smpt_s11,-1))-e_lt2*log(lag(dfl_cf_s14,-1))-e_lt1)+e_1*delta(1,log(dfl_cf_s14))+delta(1,af_eq_smpt_s11)-e_0*lag(af_eq_smpt_s11,-1)",
  coefflist = c("e_cst","e_0","e_1","e_2","e_lt2","e_lt1"),
  endogenous = "smpt_s11"
)
estimation <- quick_estim(thor_equation = eq_smpt_s11 , database = dt_pf,
                          estim_start=as.Date(date_debut_estim),
                          estim_end=as.Date(date_fin_estim),
                          coeff_lt = c("e_lt1","e_lt2"),
                          const = T)
```

Les coefficients sont significatifs mais le R^2^ n'est pas satisfaisant. On décide d'ajouter `productivite` et une indicatrice :
 
```{r}
create_equation(
  equation_name = "eq_smpt_s11",
  formula="delta(1,log(smpt_s11))=e_cst+e_0*(log(lag(smpt_s11,-1))-e_lt2*log(lag(dfl_cf_s14,-1))-e_lt3*dummy_crise_fi-e_lt1)+e_1*delta(1,log(dfl_cf_s14))+e_2*delta(1,log(productivite))+e_3*dummy_crise_fi+delta(1,af_eq_smpt_s11)-e_0*lag(af_eq_smpt_s11,-1)",
  coefflist = c("e_cst","e_0","e_1","e_2","e_3","e_lt1","e_lt2","e_lt3"),
  endogenous = "smpt_s11"
)
estimation <- quick_estim(thor_equation = eq_smpt_s11 , database = dt_pf,
                          estim_start=as.Date(date_debut_estim),
                          estim_end=as.Date(date_fin_estim),
                          coeff_lt = c("e_lt1","e_lt2","e_lt3"),
                          const = T)
```

L'indicatrice et la productivité ne permettent pas d'améliorer la régression. Pour ce qui est de l'indicatrice, son rôle minime peut être du au fait que le déflateur de la consommation explique déjà le choc de 2008. Dans d'autres configuration la variable pourrait quand même être utile. En effet, avec des scénarios de déflateurs différents, nous avions conclu qu'il n'y avait pas eu de rattrapage total du niveau d'avant crise. Par conséquent il était utile d'inclure l'indicatrice dans la partie de long terme en plus de l'inclure dans la partie de court terme afin de gérer le choc de court terme. Nous laissons `productivite` dans le modèle à ce stade expérimentale. Il serait intéressant d'insérer le taux de chômage dans la spécification quand celui-ci sera disponible.

# Equation Emploi : `eq_emploi`

## `emploi`

```{r}
ggplot(data = dt_pf1
       , aes(x =date, y=log(emploi))) +
  geom_line() +
  ggtitle(paste0("Evolution de l'emploi"))

a <- ur.df(log(dt_pf1$emploi), 
           lags = 6, 
           selectlags = "AIC", 
           type = "trend")
summary(a)
```

Nous acceptons l'hypothèse nulle de non-stationarité dans un modèle avec constante et dérive temporelle.

## `pib`

Nous avons déjà étudié la variable `pib` dans `eq_fbcf_s11`. Nous avions accepté l'hypothèse nulle de non-stationarité dans un modèle sans constante ni dérive temporelle.

## Regression de la relation de long terme


```{r}
reg_emploi_lt1 <- lm(log(emploi) ~ log(pib), dt_pf1)
summary(reg_emploi_lt1)

```

`pib` est une variable explicative acceptable pour la partie de long terme. Graphiquement, nous avons pu voir une tendance commune, cependant les pertubations du pib biaisent le R^2^.

## Tests de cointégration

```{r}
res1_emploi <- resid(reg_emploi_lt1)
plot(res1_emploi)
reg_emploi_res1 <-
  ur.df(res1_emploi,
        lags = 6,
        type = "none",
        selectlags = "AIC")
summary(reg_emploi_res1)
```
L'hypothèse nulle d'absence de cointégration ne peut pas être rejetée. Ceci se confirme graphiquement.

## Détermination de la spécification


```{r}
create_equation(
  equation_name = "eq_emploi",
  formula = "delta(1,log(emploi))=f_cst+f_0*(log(lag(emploi,-1))-f_lt2*log(lag(pib,-1))-f_lt1)+f_1*delta(1,log(pib))+delta(1,af_eq_emploi)-f_0*lag(af_eq_emploi,-1)",
  coefflist = c("f_cst", "f_0", "f_1", "f_2", "f_lt2", "f_lt1"),
  endogenous = "emploi"
)
estimation <-
  quick_estim(
    thor_equation = eq_emploi ,
    database = dt_pf,
    estim_start = as.Date(date_debut_estim),
    estim_end = as.Date(date_fin_estim),
    coeff_lt = c("f_lt1", "f_lt2"),
    const = T
  )
```

La régression est satisfaisante malgré un faible R^2^ (probablement du aux oscillations inexpliquées). On décide d'ajouter des retards de la variable `emploi` afin d'augmenter le R^2^ : 
 
```{r}
create_equation(
  equation_name = "eq_emploi",
  formula = "delta(1,log(emploi))=f_cst+f_0*(log(lag(emploi,-1))-f_lt2*log(lag(pib,-1))-f_lt1)+f_1*delta(1,log(lag(emploi,-1)))+f_2*delta(1,log(pib))+delta(1,af_eq_emploi)-f_0*lag(af_eq_emploi,-1)",
  coefflist = c("f_cst", "f_0", "f_1", "f_2", "f_3", "f_lt2", "f_lt1"),
  endogenous = "emploi"
)
estimation <-
  quick_estim(
    thor_equation = eq_emploi ,
    database = dt_pf,
    estim_start = as.Date(date_debut_estim),
    estim_end = as.Date(date_fin_estim),
    coeff_lt = c("f_lt1", "f_lt2"),
    const = T
  )
```

Nous retenons cette spécification plutôt satisfaisante à ce stade. Avec `eq_fbcf_s11`, deux équations sont expliquées en majeure partie par `pib`. Notons que grâce aux données de la CPS il serait peut-être possible de trouver les heures travaillées par emploi, variable explicative possiblement très intéressante dans cette spécification. 

# Equation Indice des prix à l'alimentation : `eq_ipc_alim`

## `ipc_alim`

```{r}
ggplot(data = dt_pf1
       , aes(x =date, y=log(ipc_alim))) +
  geom_line() +
  ggtitle(paste0("Evolution de l'indice des prix à la consommation pour l'alimentation"))

a <- ur.df(log(dt_pf1$ipc_alim), 
           lags = 6, 
           selectlags = "AIC", 
           type = "trend")
summary(a)
b <- ur.df(log(dt_pf1$ipc_alim), 
           lags = 6, 
           selectlags = "AIC", 
           type = "drift")
summary(b)
```

Nous ne pouvons pas accepter l'hypothèse nulle de non-stationarité dans un modèle avec constante sans dérive temporelle. Nous pouvons en effet la rejeter au seuil de 10%. la valeur du test est très proche du seuil de 5%.

## `brent`

Attention : `brent` n'est surement pas l'indicateur le plus approprié à l'économie Polynésienne. Il s'agirait de choisir un indicateur du prix du baril américain.

```{r}
ggplot(data = dt_pf1
       , aes(x =date, y=log(brent))) +
  geom_line() +
  ggtitle(paste0("Evolution du prix du baril"))

a <- ur.df(log(dt_pf1$brent), 
           lags = 6, 
           selectlags = "AIC", 
           type = "trend")
summary(a)
b <- ur.df(log(dt_pf1$brent), 
           lags = 6, 
           selectlags = "AIC", 
           type = "drift")
summary(b)
c <- ur.df(log(dt_pf1$brent), 
           lags = 6, 
           selectlags = "AIC", 
           type = "none")
summary(c)
```

Nous acceptons l'hypothèse nulle de non-stationarité dans un modèle sans constante ni dérive temporelle.

## `tcen`

Le taux de change nominal peut expliquer les variations de l'indice des prix à la consommation, surtout dans une économie basée sur l'importation.

```{r}
ggplot(data = dt_pf1
       , aes(x =date, y=log(tcen))) +
  geom_line() +
  ggtitle(paste0("Evolution du prix du taux de change nominal"))

a <- ur.df(log(dt_pf1$tcen), 
           lags = 6, 
           selectlags = "AIC", 
           type = "trend")
summary(a)
```

Nous rejetons l'hypothèse nulle de non-stationarité dans un modèle avec constante et dérive temporelle.

## Regression de la relation de long terme


```{r}
reg_ipc_alim_lt1 <- lm(log(ipc_alim) ~ log(brent), dt_pf1)
summary(reg_ipc_alim_lt1)

reg_ipc_alim_lt2 <- lm(log(ipc_alim) ~ log(tcen), dt_pf1)
summary(reg_ipc_alim_lt2)

reg_ipc_alim_lt3 <-
  lm(log(ipc_alim) ~ log(brent) + log(tcen), dt_pf1)
summary(reg_ipc_alim_lt3)
```

La combinaison des deux variables permet d'expliquer la moitié de la variance de la variable dépendante. Les coefficients sont de plus significatifs. Néanmoins le signe du coefficient de `brent` n'est pas cohérent. De plus, il s'agirait de revoir le sens du taux de change afin de déterminer la cohérence du coefficient devant `tcen`.

## Tests de cointégration

```{r}
res1_ipc_alim <- resid(reg_ipc_alim_lt1)
reg_ipc_alim_res1 <-
  ur.df(res1_ipc_alim,
        lags = 6,
        type = "none",
        selectlags = "AIC")
summary(reg_ipc_alim_res1)
plot(res1_ipc_alim)

res2_ipc_alim <- resid(reg_ipc_alim_lt2)
reg_ipc_alim_res2 <-
  ur.df(res2_ipc_alim,
        lags = 6,
        type = "none",
        selectlags = "AIC")
summary(reg_ipc_alim_res2)
plot(res2_ipc_alim)

res3_ipc_alim <- resid(reg_ipc_alim_lt3)
reg_ipc_alim_res3 <-
  ur.df(res3_ipc_alim,
        lags = 6,
        type = "none",
        selectlags = "AIC")
summary(reg_ipc_alim_res3)
plot(res3_ipc_alim)
```

Individuellement, `brent` n'est pas cointérgré avec `ipc_alim`. Cependant l'hypothèse nulle d'absence de cointégration est rejetée pour les 2 autres spécifications.

## Détermination de la spécification


```{r}
create_equation(
  equation_name = "eq_ipc_alim",
  formula = "delta(1,log(ipc_alim))=g_cst+g_0*(log(lag(ipc_alim,-1))-g_lt1-g_lt2*log(lag(brent,-1))-g_lt3*log(lag(tcen,-1)))+g_1*delta(1,brent)+g_2*delta(1,tcen)+delta(1,af_eq_ipc_alim)-g_0*lag(af_eq_ipc_alim,-1)",
  coefflist = c("g_cst", "g_0", "g_1", "g_2", "g_3", "g_lt2", "g_lt1", "g_lt3"),
  endogenous = "ipc_alim"
)

estimation <-
  quick_estim(
    thor_equation = eq_ipc_alim ,
    database = dt_pf,
    estim_start = as.Date(date_debut_estim),
    estim_end = as.Date(date_fin_estim),
    coeff_lt = c("g_lt1", "g_lt2", "g_lt3"),
    const = T
  )

```

La régression n'est pas satisfaisante malgré un faible R^2^. Même si la relation de long terme est très bonne, nous ne pouvons pas expliquer les relations de court terme. Une solution possible est de ne pas passer par un MCE ou de ne pas inclure cette équation. Nous ne retenons pas cet MCE à ce stade. Afin de l'inclure, il faudrait trouver des indicateurs propre à la Polynésie, c'est à dire des indicateurs avec des impacts direct. Nous la laissons dans le modèle et dans le programme afin de se donner la possibilité de résoudre le problème.
 
# Equation Indice des prix à l'énergie : `eq_ipc_nrj`

## `ipc_nrj`

```{r}
ggplot(data = dt_pf1
       , aes(x =date, y=log(ipc_nrj))) +
  geom_line() +
  ggtitle(paste0("Evolution de l'indice des prix à la consommation pour l'énergie"))

a <- ur.df(log(dt_pf1$ipc_nrj), 
           lags = 6, 
           selectlags = "AIC", 
           type = "trend")
summary(a)
b <- ur.df(log(dt_pf1$ipc_nrj), 
           lags = 6, 
           selectlags = "AIC", 
           type = "drift")
summary(b)
c <- ur.df(log(dt_pf1$ipc_nrj), 
           lags = 6, 
           selectlags = "AIC", 
           type = "none")
summary(c)
```

Nous acceptons l'hypothèse nulle de non-stationarité dans un modèle sans constante ni dérive temporelle.

## `petrole`

Nous étudions maintenant la variable `petrole` directement issu du site de l'ISPF afin d'obtenir des données davantage en lien avec l'économie Polynésienne. Le prix à la pompe étant fixé en Polynésie, il est en effet difficile de se baser sur des indicateurs comme le brent.

```{r}
ggplot(data = dt_pf1
       , aes(x =date, y=log(petrole))) +
  geom_line() +
  ggtitle(paste0("Evolution du prix du baril"))

a <- ur.df(log(dt_pf1$petrole), 
           lags = 6, 
           selectlags = "AIC", 
           type = "trend")
summary(a)
b <- ur.df(log(dt_pf1$petrole), 
           lags = 6, 
           selectlags = "AIC", 
           type = "drift")
summary(b)
c <- ur.df(log(dt_pf1$petrole), 
           lags = 6, 
           selectlags = "AIC", 
           type = "none")
summary(c)
```

Nous acceptons l'hypothèse nulle de non-stationarité dans un modèle sans constante ni dérive temporelle.


## Regression de la relation de long terme


```{r}
reg_ipc_nrj_lt1 <- lm(log(ipc_nrj) ~ log(petrole), dt_pf1)
summary(reg_ipc_nrj_lt1)

reg_ipc_nrj_lt2 <- lm(log(ipc_nrj) ~ log(brent), dt_pf1)
summary(reg_ipc_nrj_lt2)

reg_ipc_nrj_lt3 <- lm(log(ipc_nrj) ~ log(petrole) + log(brent), dt_pf1)
summary(reg_ipc_nrj_lt3)
```

La combination des deux variables permet d'expliquer 3/4 de la variance de la variable dépendante. Les coefficients sont de plus significatif et du signe cohérent. Les deux variables se complètent car elle permettent d'avoir deux niveaux différents d'analyse des chocs et des variations.

## Tests de cointégration

```{r}
res1_ipc_nrj <- resid(reg_ipc_nrj_lt1)
reg_ipc_nrj_res1 <-
  ur.df(res1_ipc_nrj,
        lags = 6,
        type = "none",
        selectlags = "AIC")
summary(reg_ipc_nrj_res1)
plot(res1_ipc_nrj)

res2_ipc_nrj <- resid(reg_ipc_nrj_lt2)
reg_ipc_nrj_res2 <-
  ur.df(res2_ipc_nrj,
        lags = 6,
        type = "none",
        selectlags = "AIC")
summary(reg_ipc_nrj_res2)
plot(res2_ipc_nrj)

res3_ipc_nrj <- resid(reg_ipc_nrj_lt3)
reg_ipc_nrj_res3 <-
  ur.df(res3_ipc_nrj,
        lags = 6,
        type = "none",
        selectlags = "AIC")
summary(reg_ipc_nrj_res3)
plot(res3_ipc_nrj)
```

Individuellement, les variables ne sont pas cointégrées avec `ipc_nrj`. Cependant, l'hypothèse nulle d'absence de cointégration est rejetée pour la combinaison des deux variables explicatives.

## Détermination de la spécification


```{r}
create_equation(
  equation_name = "eq_ipc_nrj",
  formula = "delta(1,log(ipc_nrj))=h_cst+h_0*(log(lag(ipc_nrj,-1))-h_lt1-h_lt2*log(lag(petrole,-1))-h_lt3*log(lag(brent,-1)))+h_1*delta(1,log(petrole))+h_2*delta(1,log(brent))+delta(1,af_eq_ipc_nrj)-h_0*lag(af_eq_ipc_nrj,-1)",
  coefflist = c("h_cst", "h_0", "h_1", "h_2", "h_3", "h_lt2", "h_lt1", "h_lt3"),
  endogenous = "ipc_nrj"
)

estimation <-
  quick_estim(
    thor_equation = eq_ipc_nrj ,
    database = dt_pf,
    estim_start = as.Date(date_debut_estim),
    estim_end = as.Date(date_fin_estim),
    coeff_lt = c("h_lt1", "h_lt2", "h_lt3"),
    const = T
  )
```
La spécification est très satisfaisante.


# Equation Indice des prix totaux : `eq_ipc_tot`

## `ipc_tot`

```{r}
ggplot(data = dt_pf1
       , aes(x =date, y=log(ipc_tot))) +
  geom_line() +
  ggtitle(paste0("Evolution de l'indice des prix à la consommation"))

a <- ur.df(log(dt_pf1$ipc_tot), 
           lags = 6, 
           selectlags = "AIC", 
           type = "trend")
summary(a)
b <- ur.df(log(dt_pf1$ipc_tot), 
           lags = 6, 
           selectlags = "AIC", 
           type = "drift")
summary(b)
```

Nous rejetons l'hypothèse nulle de non-stationarité dans un modèle avec constante sans dérive temporelle.

## `csu_s11`

Le coût salarié unitaire permet encore une fois de relier le prix du marché du travail au niveau général des prix. Ceci boucle la relation entre `smpt_s11` et `dfl_cf_s14`.

```{r}
ggplot(data = dt_pf1
       , aes(x =date, y=log(csu_s11))) +
  geom_line() +
  ggtitle(paste0("Evolution du coût salariale unitaire"))

a <- ur.df(log(dt_pf1$csu_s11), 
           lags = 6, 
           selectlags = "AIC", 
           type = "trend")
summary(a)
```

Nous rejetons l'hypothèse nulle de non-stationarité dans un modèle avec constante et dérive temporelle. 


## Regression de la relation de long terme


```{r}
reg_ipc_tot_lt1 <- lm(log(ipc_tot) ~ log(csu_s11), dt_pf1)
summary(reg_ipc_tot_lt1)
```

Le coût salarié unitaire explique plutôt bien l'indice des prix à la consommation en niveau.

## Tests de cointégration

```{r}
res1_ipc_tot <- resid(reg_ipc_tot_lt1)
plot(res1_ipc_tot)
reg_ipc_tot_res1 <-
  ur.df(res1_ipc_tot,
        lags = 6,
        type = "none",
        selectlags = "AIC")
summary(reg_ipc_tot_res1)

```

Nous rejetons l'hypothèse nulle d'absence de cointégration uniquement au seuil de 10 %. Graphiquement les résidus ont l'air de suivre une tendance. 

## Détermination de la spécification


```{r}
create_equation(
  equation_name = "eq_ipc_tot",
  formula = "delta(1,log(ipc_tot))=i_cst+i_0*(log(lag(ipc_tot,-1))-i_lt1-i_lt2*log(lag(csu_s11,-1)))+i_1*delta(1,log(csu_s11))+delta(1,af_eq_ipc_tot)-i_0*lag(af_eq_ipc_tot,-1)",
  coefflist = c("i_cst", "i_0", "i_1", "i_2", "i_3", "i_lt2", "i_lt1", "i_lt3"),
  endogenous = "ipc_tot"
)

estimation <-
  quick_estim(
    thor_equation = eq_ipc_tot ,
    database = dt_pf,
    estim_start = as.Date(date_debut_estim),
    estim_end = as.Date(date_fin_estim),
    coeff_lt = c("i_lt1", "i_lt2"),
    const = T
  )
```

La spécification est plutôt satisfaisante mais on souhaite améliorer l'explication des dynamiques de court terme grâce à `ipc_alim` et `ipc_nrj`.

```{r}
create_equation(
  equation_name = "eq_ipc_tot",
  formula = "delta(1,log(ipc_tot))=i_cst+i_0*(log(lag(ipc_tot,-1))-i_lt1-i_lt2*log(lag(csu_s11,-1)))+i_1*delta(1,log(csu_s11))+i_2*delta(1,log(ipc_nrj))+i_3*delta(1,log(ipc_alim))+delta(1,af_eq_ipc_tot)-i_0*lag(af_eq_ipc_tot,-1)",
  coefflist = c("i_cst", "i_0", "i_1", "i_2", "i_3", "i_lt2", "i_lt1", "i_lt3"),
  endogenous = "ipc_tot"
)

estimation <-
  quick_estim(
    thor_equation = eq_ipc_tot ,
    database = dt_pf,
    estim_start = as.Date(date_debut_estim),
    estim_end = as.Date(date_fin_estim),
    coeff_lt = c("i_lt1", "i_lt2"),
    const = T
  )
```

Cela a pour conséquence de diminuer la significativité du coefficient de `csu_s11`. Cependant l'inclusion de ces dynamiques de court terme permet d'expliquer une très large partie de la variance de `ipc_tot`. Nous pouvons questionner cet ajout étant donné que `ipc_tot` est comptablement déterminé sur la base de `ipc_alim` et `ipc_nrj`. Il est toutefois intéressant de les garder si ces deux dernières variables sont endogénéisées. En effet cela permet de laisser de la liberté au modèle tout en gardant la logique comptable au sein même des équations économétriques pour l'exercice de prévision.

# Equation importations : `eq_m`

## `m`

A cause de l'investissement d'avions, nous allons travailler ici avec `dt_pf2` pour exclure 2018 de notre période d'analyse tout comme pour `eq_fbcf_s11`.

```{r}
ggplot(data = dt_pf2
       , aes(x =date, y=log(m))) +
  geom_line() +
  ggtitle(paste0("Evolution des importations"))

a <- ur.df(log(dt_pf2$m), 
           lags = 6, 
           selectlags = "AIC", 
           type = "trend")
summary(a)
b <- ur.df(log(dt_pf2$m), 
           lags = 6, 
           selectlags = "AIC", 
           type = "drift")
summary(b)
c <- ur.df(log(dt_pf2$m), 
           lags = 6, 
           selectlags = "AIC", 
           type = "none")
summary(c)
```

Nous acceptons l'hypothèse nulle de non-stationarité dans un modèle sans constante ni dérive temporelle.

## `df`

La demande finale, i.e. tout les postes de la demande du PIB sauf les importations, est censée être un bon indicateur de la demande de resssources extérieure.

```{r}
ggplot(data = dt_pf2
       , aes(x =date, y=log(df))) +
  geom_line() +
  ggtitle(paste0("Evolution de la demande finale"))

a <- ur.df(log(dt_pf2$df), 
           lags = 6, 
           selectlags = "AIC", 
           type = "trend")
summary(a)
b <- ur.df(log(dt_pf2$df), 
           lags = 6, 
           selectlags = "AIC", 
           type = "drift")
summary(b)
c <- ur.df(log(dt_pf2$df), 
           lags = 6, 
           selectlags = "AIC", 
           type = "none")
summary(c)
```

Nous acceptons l'hypothèse nulle de non-stationarité dans un modèle sans constante ni dérive temporelle.


## Regression de la relation de long terme


```{r}
reg_m_lt1 <- lm(log(m) ~ log(df), dt_pf2)
summary(reg_m_lt1)
```

La régression est acceptable (R^2^ faible à cause des ocsillations).

## Tests de cointégration

```{r}
res1_m <- resid(reg_m_lt1)
plot(res1_m)
reg_m_res1 <-
  ur.df(res1_m,
        lags = 6,
        type = "none",
        selectlags = "AIC")
summary(reg_m_res1)

```

Nous rejetons l'hypothèse nulle d'absence de cointégration.

## Détermination de la spécification

Nous estimons sans l'année 2018.

```{r}
create_equation(
  equation_name = "eq_m",
  formula = "delta(1,log(m))=j_cst+j_0*(log(lag(m,-1))-j_lt1-j_lt2*log(lag(df,-1)))+j_1*delta(1,log(df))+delta(1,af_eq_m)-j_0*lag(af_eq_m,-1)",
  coefflist = c("j_cst", "j_0", "j_1", "j_2", "j_3", "j_lt2", "j_lt1", "j_lt3"),
  endogenous = "m"
)

estimation <-
  quick_estim(
    thor_equation = eq_m ,
    database = dt_pf,
    estim_start = as.Date(date_debut_estim),
    estim_end = as.Date("2017-12-31"),
    coeff_lt = c("j_lt1", "j_lt2"),
    const = T
  )
```

La spécification est plutôt satisfaisante mais on souhaite l'améliorer en ajoutant `tcen`, le taux de change :

```{r}
create_equation(
  equation_name = "eq_m",
  formula = "delta(1,log(m))=j_cst+j_0*(log(lag(m,-1))-j_lt1-j_lt2*log(lag(df,-1)))+j_1*delta(1,log(df))+j_2*delta(1,log(tcen))+delta(1,af_eq_m)-j_0*lag(af_eq_m,-1)",
  coefflist = c("j_cst", "j_0", "j_1", "j_2", "j_3", "j_lt2", "j_lt1", "j_lt3"),
  endogenous = "m"
)

estimation <-
  quick_estim(
    thor_equation = eq_m ,
    database = dt_pf,
    estim_start = as.Date(date_debut_estim),
    estim_end = as.Date("2017-12-31"),
    coeff_lt = c("j_lt1", "j_lt2"),
    const = T
  )
```

Nous gardons cette seconde spécification car elle augmente le R^2^ ajusté même si le coefficient de `tcen` n'est pas significatif.

# Code exemple pour présentation

## Equations latex

Il est possible d'obtenir le code nécessaire à l'affichage des équations en Latex. Voici un exemple :

```{r}
cat(formula_latex(eq_m))
```
$$\Delta_{1}( \mathit{log(} \textbf{m}_{t} ))= \textit{j_cst} + \textit{j_0} *( \mathit{log(} \textbf{m}_{t-1} )- \textit{j_lt1} - \textit{j_lt2} * \mathit{log(} \textbf{df}_{t-1} ))+ \textit{j_1} * \Delta_{1}( \mathit{log(} \textbf{df}_{t} ))+ \textit{j_2} * \Delta_{1}( \mathit{log(} \textbf{tcen}_{t} ))+ \Delta_{1}( \textbf{af_eq_m}_{t} )- \textit{j_0} * \textbf{af_eq_m}_{t-1}$$

## Présentation résultat régression

Pour comparer les régressions et mettre en page, la fonction `stargazer()` est intéressante.

Par exemple pour `eq_ipc_nrj` :

```{r}
stargazer(reg_ipc_nrj_lt1,reg_ipc_nrj_lt2,reg_ipc_nrj_lt3,
          title="Regression Results",
          align=TRUE,
          omit.stat=c("LL","ser","f"), 
          no.space=TRUE,
          type="text")
```

Il est également possible d'obtenir le code `LateX` pour éditer ce tableau :

```{r , eval = F }
stargazer(reg_ipc_nrj_lt1,reg_ipc_nrj_lt2,reg_ipc_nrj_lt3,
          title="Regression Results",
          align=TRUE,
          omit.stat=c("LL","ser","f"), 
          no.space=TRUE,
          type="latex")
```

$$\begin{table}[!htbp] \centering 
  \caption{Regression Results} 
  \label{} 
\begin{tabular}{@{\extracolsep{5pt}}lD{.}{.}{-3} D{.}{.}{-3} D{.}{.}{-3} } 
\\[-1.8ex]\hline 
\hline \\[-1.8ex] 
 & \multicolumn{3}{c}{\textit{Dependent variable:}} \\ 
\cline{2-4} 
\\[-1.8ex] & \multicolumn{3}{c}{log(ipc\_nrj)} \\ 
\\[-1.8ex] & \multicolumn{1}{c}{(1)} & \multicolumn{1}{c}{(2)} & \multicolumn{1}{c}{(3)}\\ 
\hline \\[-1.8ex] 
 log(petrole) & 0.399^{***} &  & 0.387^{***} \\ 
  & (0.056) &  & (0.039) \\ 
  log(brent) &  & 0.132^{***} & 0.125^{***} \\ 
  &  & (0.029) & (0.017) \\ 
  Constant & 2.808^{***} & 4.086^{***} & 2.328^{***} \\ 
  & (0.258) & (0.126) & (0.191) \\ 
 \hline \\[-1.8ex] 
Observations & \multicolumn{1}{c}{52} & \multicolumn{1}{c}{52} & \multicolumn{1}{c}{52} \\ 
R$^{2}$ & \multicolumn{1}{c}{0.507} & \multicolumn{1}{c}{0.292} & \multicolumn{1}{c}{0.766} \\ 
Adjusted R$^{2}$ & \multicolumn{1}{c}{0.497} & \multicolumn{1}{c}{0.278} & \multicolumn{1}{c}{0.757} \\ 
\hline 
\hline \\[-1.8ex] 
\textit{Note:}  & \multicolumn{3}{r}{$^{*}$p$<$0.1; $^{**}$p$<$0.05; $^{***}$p$<$0.01} \\ 
\end{tabular} 
\end{table}$$

</div>

